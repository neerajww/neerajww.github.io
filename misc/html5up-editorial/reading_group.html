<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>DS &amp AI | IIT G</title>
		<link rel='shortcut icon' type='image/x-icon' href='./images/IIT_Guwahati_Logo.ico' />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <!-- added for collapse button -->
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css">
        <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.slim.min.js"></script>
        <!-- <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script> -->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js"></script>
        <!-- till here -->
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
                            <header id="header">
                                <a href="index.html" class="logo">Mehta Family <strong>School of DS&ampAI</strong></a>
                                <!-- <ul class="icons" >
                                    <li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
                                    <li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
                                    <li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li>
                                    <li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
                                    <li><a href="#" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li>
                                </ul> -->
                            </header>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Reading Group Meetings</h2>
									</header>
									<p>The Reading Group is conceived (started in April 2022) to serve the following objectives.
										<ul>
											<li><b>Discussing recent papers of interest:</b> The goal is to create cognizance of the recent developments in the field, understand any paper via a collective effort and make an assessment of its relevance in the context of research pursued in the School.</li>
											<li><b>Share your findings:</b> Provide a platform for researchers from across the institute, exploring DS & AI in different domains, to come forward and share their ongoing work as a seminar, and receive feedback.</li>
											<li><b>Struck? We might be able to help you:</b> Provide a sounding board to researchers struck in their research problem by encouraging them to discuss with a white board, slides and many more DS and AI brains.</li>
										</ul>
										These meetings are interactive and enrich the research outlook of the participants.  The scope of the presentations include foundational, theoretical and applied research work. We (Students and Faculty) meet once every month at 5 PM, on the last Friday of the month. To get updates about these meetings and participate, use the link <a href="https://outlook.office365.com/owa/Grp_dsaireadinggroupiitg@iitg.ac.in/groupsubscription.ashx?action=join&source=MSExchange/LokiServer&guid=ab030aab-b55d-447e-a3b5-9647c31f2c26">here (for IIT G intranet)</a>. To provide suggestions or reserve a slot for your presentation, please feel free to reach out to Arghyadip Roy or Neeraj Sharma, <a href="./core_faculty.html">Faculty</a> of our School.
									</p>
                                    <div class="table-wrapper">
                                        <table>
                                            <thead>
                                                <tr>
                                                    <th>Timing</th>
                                                    <th>Presenter</th>
                                                    <th>Affiliation</th>
                                                    <th>Topic</th>
                                                    <th>Abstract</th>
                                                    <th>Resource</th>
                                                </tr>
                                            </thead>
                                            <tbody>
                                                <tr>
                                                    <td>22-Nov-2022</td>
                                                    <td>
                                                        Anupam Kumar
                                                        <span class="image fit"><img src="images/phd_scholars/anupam_2022.png" alt="" /></span>
                                                        </td>
                                                    <td>PhD Scholar, DS&ampAI</td>
                                                    <td>Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods</td>
                                                    <td>
                                                        <!-- <div class="container"> -->
                                                            <button type="button" class="btn" data-toggle="collapse" data-target="#talk_6">Abstract</button>
                                                            <div id="talk_6" class="collapse">
                                                                These days machine learning is being used very widely in a lot of high stakes decision making areas like healthcare, law, business etc. But the main problem with these machine learning models is that they are mostly black boxes. Although for interpreting these black box models we can use either rule-based explanation techniques or different popular post hoc model agnostic explanations techniques like LIME and SHAP. In this talk, we will discuss about the framework that can effectively hide the discriminatory biases of any black box classifier by fooling LIME and SHAP, due to which these post hoc explanation techniques might be unstable and unreliable which result in misleading explanations. There has not been much prior work to understand the real-world consequences of misleading explanations. So, we will also look into it that how misleading explanations can affect user trust. We will also discuss how can adversarial perturbation based post hoc techniques to generate any arbitrary explanation of their choice.
																<br>References:
                                                            <ul>
																<li><a href="https://dl.acm.org/doi/pdf/10.1145/3375627.3375830">Fooling LIME and SHAP: Adversarial Attacks on Post hoc Explanation Methods</a></li>
																<li><a href="https://dl.acm.org/doi/pdf/10.1145/3375627.3375833">“How do I fool you?": Manipulating User Trust via Misleading Black Box Explanations</a></li>
																<li><a href="https://arxiv.org/pdf/1705.07874.pdf">SHAP</a></li>
															</ul>
															</div>
                                                          <!-- </div> -->
                                                    </td>
                                                    <td>-</td>
                                                </tr>

                                                <tr>
                                                    <td>28-Oct-2022</td>
                                                    <td>
                                                        Ashim Kumar
                                                        <span class="image fit"><img src="images/reading_group/rg_ashim_2022.jpg" alt="" /></span>
                                                        </td>
                                                    <td>PhD Scholar, EEE</td>
                                                    <td>Hybrid beamforming using machine learning for mm-wave massive-MIMO systems</td>
                                                    <td>
                                                        <!-- <div class="container"> -->
                                                            <button type="button" class="btn" data-toggle="collapse" data-target="#talk_6">Abstract</button>
                                                            <div id="talk_6" class="collapse">
                                                                Current cellular systems employ narrow spatial beams using high-dimensional antenna arrays (massive MIMO) to serve multiple users simultaneously. Although a digital beamformer is used conventionally, due to the high associated cost and power requirements, a hybrid beamforming architecture is being widely considered. Robust communication using beams necessitates proper beam management protocols. We explore the utility of machine learning algorithms in light of such challenges. Supervised and reinforcement learning algorithms have been explored to speed up the selection process of spatial beams to maximize the mean data rate of a multi-antenna wireless system that implements hybrid beamforming in mmWave frequency bands. In this talk, we will discuss our ongoing research works being carried out in this direction.
                                                            </div>
                                                          <!-- </div> -->
                                                    </td>
                                                    <td>-</td>
                                                </tr>
                                                <tr>
                                                    <td>30-Sept-2022</td>
                                                    <td>
                                                        Konda Reddy Mopuri
                                                        <span class="image fit"><img src="images/reading_group/rg_konda.jpeg" alt="" /></span>
                                                        </td>
                                                    <td>Assistant Professor, DS &amp AI</td>
                                                    <td>Subset selection for compute-efficient deep learning</td>
                                                    <td>
                                                        <button type="button" class="btn" data-toggle="collapse" data-target="#talk_5">Abstract</button>
                                                        <div id="talk_5" class="collapse">
                                                            Machine learning methods (especially the deep learning models) rely on large datasets: the more the data, the better the learning. However, storing large datasets and training models on them becomes significantly more expensive. Some of the applications such as continual learning need to train or fine-tune the models frequently, making it a computationally demanding exercise. In this talk, we will briefly discuss the following questions in the context of deep learning: (i) Are all the data samples equally important for learning? (ii) Can we identify a subset of the training data for learning the model that is as good as (or, close to) the one learned on the full dataset? (iii) Can we distill the large dataset into a smaller but synthetic dataset for compute-efficient training? We will discuss some of the works that attempt subset selection and dataset distillation (or, condensation) toward compute-efficient learning.
                                                        </div>
                                                    </td>
                                                    <td><a href="https://docs.google.com/presentation/d/1H87ug2f6UvPsYFxBlVxczac3AgrTKOx_BmNRF1-Juj0/edit?usp=sharing">Slides</a></td>
                                                </tr>
                                                <tr>
                                                    <td>26-Aug-2022</td>
                                                    <td>
                                                        Neeraj Sharma
                                                        <span class="image fit"><img src="images/reading_group/rg_neeraj.png" alt="" /></span>
                                                        </td>
                                                    <td>Assistant Professor, DS &amp AI</td>
                                                    <td>Curious case of respiratory sound samples: Detecting COVID-19 from breathing, cough, and speech sound recordings</td>
                                                    <td>
                                                        <button type="button" class="btn" data-toggle="collapse" data-target="#talk_4">Abstract</button>
                                                        <div id="talk_4" class="collapse">
                                                            Since the outbreak of COVID-19, an increasing number of studies have suggested that the disease triggers the SARS-CoV-2 virus to replicate and migrate down the respiratory tract, to the epithelial cells in the lungs. Meta-analysis studies have found fever, followed by cough, and malaise as the common symptoms in COVID-19 infected individuals. Altogether this indicates impairment in the respiratory system. Hence, it becomes interesting to understand if there are detectable signatures of COVID-19 in the sound samples such as breathing, cough, and speech, originating from the respiratory system. Presence of detectable COVID-19 signatures in sound samples can subsequently be used to design point-of-care tests. These will be easily scalable and cost-effective, supplementing the gold-standard RT-PCR and other molecular testing methods. To explore this, we pursued an exploratory study consisting of respiratory sound sample dataset creation, acoustic analysis of the data using signal processing and machine learning approaches, and development of a COVID-19 screening tool. We find that significantly above chance COVID-19 detection performance (AUC-ROC>80%) is obtained using sound recordings, and the performance improves on using symptom information. In this talk, I will present this exploration in detail. [This is a joint work with individuals from multiple places across India who joined hands, remotely, during the pandemic].
                                                        </div>
                                                    </td>
                                                    <td><a href="https://docs.google.com/presentation/d/1nzmLHxEH33ki9hOT1k6F8BuqX4OhwnzhJ0GoE_K-FSQ/edit?usp=sharing">Slides</a></td>
                                                </tr>
                                                <tr>
                                                    <td>29-July-2022</td>
                                                    <td>
                                                        Kamal
                                                        <span class="image fit"><img src="images/reading_group/rg_kamal.jpeg" alt="" /></span>
                                                        </td>
                                                    <td>Research Scholar, DS &amp AI</td>
                                                    <td>Lips Don’t Lie: A Generalisable and Robust Approach to Face Forgery Detection</td>
                                                    <td>
                                                        <button type="button" class="btn" data-toggle="collapse" data-target="#talk_3">Abstract</button>
                                                        <div id="talk_3" class="collapse">
                                                            Although current deep learning-based face forgery detection models are giving the best performance, In this paper, the author proposed a LipForensics method for forgery detection which is capable of both generalizing to novel manipulations and withstanding various distortions. LipForensics targets high-level semantic irregularities in mouth movements, which are common in many generated videos. It consists of first pretraining a Spatio-temporal network to perform visual speech recognition (lipreading), thus learning-rich internal representations related to natural mouth motion. A temporal network is subsequently finetuned on fixed mouth embeddings of real and forged data in order to detect fake videos based on mouth movements without overfitting to low-level, manipulation-specific artifacts.
                                                        </div>
                                                    </td>
                                                    <td><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Haliassos_Lips_Dont_Lie_A_Generalisable_and_Robust_Approach_To_Face_CVPR_2021_paper.pdf">Paper</a></td>
                                                </tr>
                                                <tr>
                                                    <td>24-June-2022</td>
                                                    <td>
                                                        Arghyadip Roy
                                                        <span class="image fit"><img src="images/reading_group/rg_arghyadip.jpeg" alt="" /></span>
                                                        </td>
                                                    <td>Assistant Professor, DS &amp AI</td>
                                                    <td>Adaptive KL-UCB based Bandit Algorithms for Markovian and i.i.d Bandits</td>
                                                    <td>
                                                        <button type="button" class="btn" data-toggle="collapse" data-target="#talk_2">Abstract</button>
                                                        <div id="talk_2" class="collapse">
                                                            In the regret-based formulation of Multi-armed Bandit (MAB) problems, except in rare instances, much of the literature focuses on arms with i.i.d. rewards. In this talk, we consider the problem of obtaining regret guarantees for MAB problems in which the rewards of each arm form a Markov chain that may not belong to a single parameter exponential family. To achieve logarithmic regret in such problems is not difficult: a variation of standard Kullback-Leibler Upper Confidence Bound (KL-UCB) does the job. However, the constants obtained from such an analysis are poor for the following reason: i.i.d. rewards are a special case of Markov rewards and it is difficult to design an algorithm that works well independent of whether the underlying model is truly Markovian or i.i.d. To overcome this issue, we introduce a novel algorithm that identifies whether the rewards from each arm are truly Markovian or i.i.d. using a total variation distance-based test. Our algorithm then switches from using a standard KL-UCB to a specialized version of KL-UCB when it determines that the arm reward is Markovian, thus resulting in low regret for both i.i.d. and Markovian settings.
                                                        </div>
                                                    </td>
                                                    <td>-</td>
                                                </tr>
                                                <tr>
                                                    <td>29-April-2022</td>
                                                    <td>
                                                        Konda Reddy Mopuri
                                                        <span class="image fit"><img src="images/reading_group/rg_konda.jpeg" alt="" /></span>
                                                        </td>
                                                    <td>Assistant Professor, DS &amp AI</td>
                                                    <td>Data-free Knowledge Extraction from a Deep Learning Model</td>
                                                    <td>
                                                        <button type="button" class="btn" data-toggle="collapse" data-target="#talk_1">Abstract</button>
                                                        <div id="talk_1" class="collapse">
                                                            Deep Learning often requires a huge amount of training data to learn sophisticated models. Considering the human expertise and the computational resources required, the resulting models become valuable intellectual property to be protected by the researchers. In this talk, I will discuss the risks of exposing such models or their predictions to adversaries. Specifically, I will discuss a couple of directions for extracting knowledge from the trained models that amount to stealing the victim model's knowledge. Starting from very simplistic scenarios, I will take you towards the risks present in a real-world 'ML as a service (MLaaS)' deployment scenario.
                                                        </div>
                                                    </td>
                                                    <td><a href="https://docs.google.com/presentation/d/1nzmLHxEH33ki9hOT1k6F8BuqX4OhwnzhJ0GoE_K-FSQ/edit?usp=sharing">Slides</a></td>
                                                </tr>
                                            </tbody>
                                        </table>

                                </section>

						</div>
					</div>

				<!-- Sidebar -->
				<div id="sidebar">
					<div class="inner">

						<!-- Search -->
							<!-- <section id="search" class="alt">
								<form method="post" action="#">
									<input type="text" name="query" id="query" placeholder="Search" />
								</form>
							</section> -->

						<!-- Menu -->
							<nav id="menu">
								<header class="major">
									<h2>Menu</h2>
								</header>
								<ul>
									<li><a href="index.html">Home</a></li>
									<li>
										<span class="opener">Academics</span>
										<ul>
											<li><a href="./dsai_btech_curriculum.html">BTech Curriculum</a></li>
											<li><a href="./dsai_btech_courses.html">BTech Courses</a></li>
											<li><a href="./dsai_phd_curriculum.html">PhD Curriculum</a></li>
											<li><a href="./dsai_advanced_courses.html">Advanced Courses</a></li>
										</ul>
									</li>
									<li><a href="https://www.iitg.ac.in/acad/admission/" target="_blank">Admissions</a></li>
									<li>
										<span class="opener">Our People</span>
										<ul>
											<li><a href="./head_department.html">Head of School</a></li>
											<li><a href="./all_faculty.html">Faculty</a></li>
											<!-- <li><a href="./core_faculty.html">Core Faculty</a></li>
											<li><a href="./assoc_faculty.html">Associate Faculty</a></li>
											<li><a href="./international_dfac.html">Intl. Distinguished Faculty</a></li> -->
											<li><a href="./staff.html">Staff</a></li>
											<li><a href="./phd_scholars.html">PhD Scholars</a></li>
											<li><a href="./btech_students.html">BTech Students</a></li>
										</ul>
									</li>
									<li>
										<span class="opener">Research</span>
										<ul>
											<li><a href="./research.html">Areas</a></li>
											<li><a href="./education.html">Education</a></li>
											<li><a href="./facilities.html">Facilties</a></li>
											<li><a href="./funding_collaboration.html">Funding</a></li>
										</ul>
									</li>
									<li>
										<span class="opener">Resources</span>
										<ul>
											<li></li>
											<li><a href="./ai_progress.html">AI Progress</a></li>
											<li><a href="./members_resource.html">(For) Members</a></li>
											<li><a href="./committees.html">Committees</a></li>
											<li><a href="./prospective_faculty.html">Prospective Faculty</a></li>
											<li><a href="./prospective_student_staff.html">Prospective Students &amp Staff</a></li>
											<li></li>
										</ul>
									</li>
									<li>
										<span class="opener">News &amp Event</span>
										<ul>
											<li><a href="./news.html">News</a></li>
											<li><a href="./reading_group.html">Reading Group</a></li>
											<li><a href="./seminar.html">ChAI Seminar Series</a></li>
											<li><a href="./school_activity_log.html">Outreach Activities</a></li>
										</ul>
									</li>
									<li>
										<span class="opener">About Us</span>
										<ul>
											<li><a href="./our_school.html">Our School</a></li>
											<li><a href="./siaa.html">International Advisors</a></li>
											<li><a href="./media_coverage.html">Media Coverage</a></li>
											<li><a href="./mff_support.html">Mehta Family Foundation</a></li>
											<li><a href="./gallery.html" target="_blank">Gallery</a></li>
											<li><a href="./contact_us.html#">Contact Us</a></li>
										</ul>
									</li>
								</ul>
							</nav>

						<!-- Section -->
							<section>
								<header class="major">
									<h2>Spotlight</h2>
								</header>
								<div class="mini-posts">
									<article>
										<a href="#" class="image"><img src="images/highlights/varahan_lectures.png" alt="" /></a>
										<p><a href="https://www.ou.edu/coe/cs/people/varahan">S. Lakshmivarahan (Varahan)</a>, globally recognized Applied Mathematician, to deliver lectures in the School in 2nd Week of Jan 2022</p>
									</article>
									<article>
										<a href="#" class="image"><img src="images/highlights/Prof_Mahesh_Sep9_2022.jpeg" alt="" /></a>
										<p><a href="https://uwaterloo.ca/civil-environmental-engineering/profile/mdpandey">Mahesh Pandey</a> (Univ. Waterloo, Canada) interacted with School members, sharing insights on use of ML for nuclear plant risk-assesment [9-Sept-2022]</p>
									</article>
									<article>
										<a href="#" class="image"><img src="images/highlights/konda_teaching_july2021.jpg" alt="" /></a>
										<p>July-Nov Semester (2022) begins and our faculty are all set to go to the board for the "teaching test" .</p>
									</article>
								</div>
								<!-- <ul class="actions">
									<li><a href="#" class="button">More</a></li>
								</ul> -->
							</section>

						<!-- Section -->
							<section>
								<header class="major">
									<h2>Get in touch</h2>
								</header>
								<!-- <p></p> -->
								<ul class="contact">
									<li class="icon solid fa-envelope"><a href="#">mfsdsai_off@iitg.ac.in</a></li>
									<li class="icon solid fa-phone">(+91)-0361-258-3400</li>
									<li class="icon solid fa-home">Mehta Family School of Data Science &amp Artificial Intelligence,<br />
										IIT Guwahati,<br />
										Assam 781039</li>
								</ul>
							</section>
						<!-- Footer -->
							<footer id="footer">
								<p class="copyright">&copy;Mehta Family School of Data Science &amp AI. All rights reserved. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
							</footer>

					</div>
				</div>

		</div>
		<!---sidebar closes-->


	<!-- Scripts -->
		<script src="assets/js/jquery.min.js"></script>
		<script src="assets/js/browser.min.js"></script>
		<script src="assets/js/breakpoints.min.js"></script>
		<script src="assets/js/util.js"></script>
		<script src="assets/js/main.js"></script>
		<!-- <script src="assets/js/slider.js"></script> -->

</body>
</html>